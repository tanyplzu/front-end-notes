## 前端数字

> 为什么 0.1 + 0.2 != 0.3

因为 JS 采用 IEEE 754 双精度版本（64位），并且只要采用 IEEE 754 的语言都有该问题。

### 数字的表示

我们都知道计算机是通过二进制来存储东西的，那么 0.1 在二进制中会表示为
```js
// (0011) 表示循环
0.1 = 2^-4 * 1.10011(0011)
```
我们可以发现，0.1 在二进制中是无限循环的一些数字，其实不只是 0.1，其实很多十进制小数用二进制表示都是无限循环的。这样其实没什么问题，但是 JS 采用的浮点数标准却会裁剪掉我们的数字。

IEEE 754 双精度版本（64位）将 64 位分为了三段
- 第一位用来表示符号
- 接下去的 11 位用来表示指数
- 其他的位数用来表示有效位，也就是用二进制表示 0.1 中的 10011(0011)

那么这些循环的数字被裁剪了，就会出现精度丢失的问题，也就造成了 0.1 不再是 0.1 了，而是变成了 `0.100000000000000002`
```js
0.100000000000000002 === 0.1 // true
0.200000000000000002 === 0.2 // true
0.300000000000000002 === 0.3 // true
```

所以这两者相加不等于 0.3 而是 `0.300000000000000004`
```js
0.1 + 0.2 === 0.30000000000000004 // true
```

那么可能你又会有一个疑问，既然 0.1 不是 0.1，那为什么 console.log(0.1) 却是正确的呢？
因为在输入内容的时候，二进制被转换为了十进制，十进制又被转换为了字符串，在这个转换的过程中发生了取近似值的过程，所以打印出来的其实是一个近似值，你也可以通过以下代码来验证
```js
console.log(0.100000000000000002) // 0.1
```
其实解决的办法有很多，这里我们选用原生提供的方式来最简单的解决问题
```js
parseFloat((0.1 + 0.2).toFixed(10)) === 0.3 // true
```

### 整数的安全范围
Javascript 中的 Number 类型都是 64 位（双精度）的。对于整数来说，有53位来表示整数的数值还有1位的符号位来表示正负。也就是，只能精确表示53位以内的整数，对于超出53位的整数，没有办法精确区分它们：
```js
Number.MAX_SAFE_INTEGER
// 9007199254740991
// 2 ** 53
Number.MIN_SAFE_INTEGER
// -9007199254740991
// (2 ** 53) + 2 
```

### 整数的检测


